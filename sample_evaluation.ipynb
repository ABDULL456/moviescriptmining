{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sample_evaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_fb8s1jbkTBG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzYrJQVLFr5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Sample:\n",
        "  def __init__(self, prompt, truth, samples=None, selection=None):\n",
        "    self.prompt = prompt\n",
        "    self.truth = truth\n",
        "    self.samples = samples or []\n",
        "    self.length = 1\n",
        "    self.selection = selection\n",
        "    \n",
        "  @staticmethod\n",
        "  def load_file(path):\n",
        "    '''\n",
        "    Create a list of Samples from a json file.\n",
        "    '''\n",
        "    with open(path) as f:\n",
        "      j = json.load(f)\n",
        "    if isinstance(j, dict):\n",
        "      j = [j]\n",
        "    return [Sample.load_dict(d) for d in j]\n",
        "  \n",
        "  @staticmethod\n",
        "  def load_dict(d):\n",
        "    return Sample(d['prompt'], d['truth'], d.get('samples'), d.get('selection'))\n",
        "  \n",
        "  def generate(self, n):\n",
        "    # TODO: use GPT-2 to generate samples (may require reworking `prompt`)\n",
        "    self.samples = [f'generated {i+1}' for i in range(n)]\n",
        "    self.length = n + 1\n",
        "  \n",
        "  def select(self):\n",
        "    def print_header(text=None, c='='):\n",
        "      if not text:\n",
        "        print(c * 62)\n",
        "        return\n",
        "      left = max(30 - len(text) // 2, 10)\n",
        "      right = max(30 - (len(text) + 1) // 2, 10)\n",
        "      print(c * left, text, c * right)\n",
        "  \n",
        "    print_header('Prompt')\n",
        "    print(self.prompt)\n",
        "    completions = [self.truth] + self.samples\n",
        "    shuffled_indices = list(range(self.length))\n",
        "    random.shuffle(shuffled_indices)\n",
        "    for si, ci in enumerate(shuffled_indices):\n",
        "      print_header(f'Completion {si+1}', c='-')\n",
        "      print(completions[ci])\n",
        "    \n",
        "    while True:\n",
        "      print_header(c='-')\n",
        "      si = input(f'Choose best completion (1-{self.length}) (q to quit) >>> ')\n",
        "      if si.startswith('q'):\n",
        "        return None\n",
        "      try:\n",
        "        si = int(si) - 1\n",
        "      except ValueError:\n",
        "        print('Not a number, try again.')\n",
        "        continue\n",
        "      if 0 <= si < self.length:\n",
        "        break\n",
        "      else:\n",
        "        print('Invalid number, try again.')\n",
        "    self.selection = shuffled_indices[si]\n",
        "    return self.selection == 0\n",
        "  \n",
        "  def __str__(self):\n",
        "    return json.dumps({\n",
        "        'prompt': self.prompt,\n",
        "        'truth': self.truth,\n",
        "        'samples': self.samples,\n",
        "        'selection': self.selection,\n",
        "    }, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "04aHySLPIHDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "1f5a9bdb-8d34-4f89-e8b9-4cbd6c9b4c4b"
      },
      "cell_type": "code",
      "source": [
        "s = Sample('the prompt', 'the truth')\n",
        "s.generate(8)\n",
        "s.select()\n",
        "\n",
        "print(Sample.load_dict(json.loads(str(s))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================== Prompt ===========================\n",
            "the prompt\n",
            "------------------------ Completion 1 ------------------------\n",
            "generated 8\n",
            "------------------------ Completion 2 ------------------------\n",
            "the truth\n",
            "------------------------ Completion 3 ------------------------\n",
            "generated 6\n",
            "------------------------ Completion 4 ------------------------\n",
            "generated 4\n",
            "------------------------ Completion 5 ------------------------\n",
            "generated 3\n",
            "------------------------ Completion 6 ------------------------\n",
            "generated 5\n",
            "------------------------ Completion 7 ------------------------\n",
            "generated 7\n",
            "------------------------ Completion 8 ------------------------\n",
            "generated 1\n",
            "------------------------ Completion 9 ------------------------\n",
            "generated 2\n",
            "--------------------------------------------------------------\n",
            "Choose best completion (1-9) (q to quit) >>> 9\n",
            "{\n",
            "    \"prompt\": \"the prompt\",\n",
            "    \"truth\": \"the truth\",\n",
            "    \"samples\": [\n",
            "        \"generated 1\",\n",
            "        \"generated 2\",\n",
            "        \"generated 3\",\n",
            "        \"generated 4\",\n",
            "        \"generated 5\",\n",
            "        \"generated 6\",\n",
            "        \"generated 7\",\n",
            "        \"generated 8\"\n",
            "    ],\n",
            "    \"selection\": 2\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}