{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_samples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oPfIIzeAKjan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gpt_2_simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import json\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ho8HjzNgKlWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "94e9d771-f2a6-4e63-9f81-2856f80878ee"
      },
      "cell_type": "code",
      "source": [
        "gpt2.mount_gdrive()\n",
        "gpt2.copy_checkpoint_from_gdrive()\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-54d36b217c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_checkpoint_from_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mcopy_checkpoint_from_gdrive\u001b[0;34m(checkpoint_folder)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mis_mounted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/checkpoint/run1'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xHTQkI8vQbvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_random(prefix, temp=0.7):\n",
        "  return gpt2.generate(sess, length=len(prefix), temperature=temp, prefix=prefix)\n",
        "def sample_sentiment(prefix, sentiment_vec, max_iter=100, thresh=0):\n",
        "  \"\"\" \n",
        "  Sentiment based rejection sampling\n",
        "  returns the best sample\n",
        "  Sample either hundred times or when we do better than threshhold distance\n",
        "  note thresh is between [0,2]. It's an early cutoff\n",
        "  \"\"\"\n",
        "  best_score = 2\n",
        "  best_result = None\n",
        "  for i in range(max_iter):\n",
        "    sample = sample_random(prefix, random.random())\n",
        "    ss = sid.polarity_scores(sample)\n",
        "    curr_sent = np.array([ss[\"compound\"], ss[\"neg\"], ss[\"neu\"], ss[\"pos\"]])\n",
        "    dist = np.linalg.norm(sentiment_vec-curr_sent)\n",
        "    if (dist < thresh):\n",
        "      return sample\n",
        "    if dist < best_score:\n",
        "      best_result = sample\n",
        "      best_score = dist\n",
        "  return best_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMPXemZtNTI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_single(sess, checkpoint, sid, train_file, test_instance, save_dest):\n",
        "  \"\"\"\n",
        "  Takes the single testing JSON file as a dict.\n",
        "  Runs sampling on all 3, saves results to dest dir, each training example to\n",
        "  its own file\n",
        "  \"\"\"\n",
        "  gpt2.finetune(sess,\n",
        "                dataset=train_file,\n",
        "                steps=20,\n",
        "                restore_from=checkpoint,\n",
        "                print_every=30,\n",
        "                sample_every=30,\n",
        "                save_every=30\n",
        "                ) # don't want to save\n",
        "  results = []\n",
        "  for i in range(1,4):\n",
        "    inp = test_instance[\"test{}_input\".format(i)]\n",
        "    tru = test_instance[\"test{}_true\".format(i)]\n",
        "    id_ = test_instance[\"test{}_id\".format(i)]\n",
        "    # Generate random sample\n",
        "    samp_rand = sample_random(inp)\n",
        "    # Generate sentiment sample\n",
        "    ss = sid.polarity_scores(sentence)\n",
        "    sentiment_vec = np.array([ss[\"compound\"], ss[\"neg\"], ss[\"neu\"], ss[\"pos\"]])\n",
        "    samp_sent = sample_sentiment(inp, sentiment_vec)\n",
        "    sample = {\"id\": id_,\n",
        "              \"prefix\": inp,\n",
        "              \"truth\": tru,\n",
        "              \"random\": samp_rand,\n",
        "              \"sentiment\": samp_sent\n",
        "             }\n",
        "    results.append(sample)\n",
        "  with open(save_dest, \"w\") as f:\n",
        "    json.dump(results, f)   \n",
        "\n",
        "def run_tests(test_dir, train_dir, sess, checkpoint):\n",
        "  # Load model from checkpoint\n",
        "  for f in listdir(train_dir):\n",
        "    fname = f[:-3]\n",
        "    train = join(train_dir, f)\n",
        "    test = join(test_dir, fname+\".json\")\n",
        "    if isfile(src) and isfile(test):\n",
        "      with open(test, \"r\") as test_file:\n",
        "        test_instance = json.loads(test_file)[0]\n",
        "        test_single(sess, checkpoint, train, test_instance, \"/content/results/{}_sample.json\".format(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYiQYsVuPjyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tG682gbVNp_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}