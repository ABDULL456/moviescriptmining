{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_samples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oPfIIzeAKjan",
        "colab_type": "code",
        "outputId": "61b60a73-2d09-447b-9b2a-a1e002b39c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gpt_2_simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from os import listdir\n",
        "from os.path import isfile, join, splitext\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import nltk.sentiment.vader as vader\n",
        "import shutil"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dq-cnJ265N_i",
        "colab_type": "code",
        "outputId": "b7995be7-9b11-4ec9-ea6b-418ad384715b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "lwY5VOHJ51oo",
        "colab_type": "code",
        "outputId": "8bb7b049-c73a-4974-f177-aec35bf0f733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 204kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 45.2Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 293kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 63.2Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 1.07Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 30.4Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 36.8Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ho8HjzNgKlWg",
        "colab_type": "code",
        "outputId": "4b3249db-633f-4848-c939-c783a3bc8b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "gpt2.mount_gdrive()\n",
        "gpt2.copy_checkpoint_from_gdrive()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3blErKfrlB2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "7aab8108-8d9d-489f-d8ce-3a2baecddb4a"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danster101/moviescriptmining.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'moviescriptmining'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 14054 (delta 12), reused 24 (delta 8), pack-reused 14022\u001b[K\n",
            "Receiving objects: 100% (14054/14054), 152.19 MiB | 22.47 MiB/s, done.\n",
            "Resolving deltas: 100% (4953/4953), done.\n",
            "Checking out files: 100% (5463/5463), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zhx9E_jKIE0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sid = vader.SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xHTQkI8vQbvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_random(sess, prefix, temp=0.7, top_k=0):\n",
        "  return gpt2.generate(sess, return_as_list=True, length=len(prefix), temperature=temp, prefix=prefix, top_k=top_k, include_prefix=False)[0]\n",
        "\n",
        "def sample_sentiment(sess, prefix, sentiment_vec, max_iter=5, thresh=0):\n",
        "  \"\"\" \n",
        "  Sentiment based rejection sampling\n",
        "  returns the best sample\n",
        "  Sample either hundred times or when we do better than threshold distance\n",
        "  note thresh is between [0,2]. It's an early cutoff\n",
        "  \"\"\"\n",
        "  best_score = 2\n",
        "  best_result = None\n",
        "  for i in range(max_iter):\n",
        "    print(f'Sentiment sample {i}')\n",
        "    sample = sample_random(sess, prefix, temp=(random.random() / 3 + 0.66))\n",
        "    if not sample:\n",
        "      continue\n",
        "    ss = sid.polarity_scores(sample)\n",
        "    curr_sent = np.array([ss[\"compound\"], ss[\"neg\"], ss[\"neu\"], ss[\"pos\"]])\n",
        "    dist = np.linalg.norm(sentiment_vec-curr_sent)\n",
        "    if (dist < thresh):\n",
        "      return sample\n",
        "    if dist < best_score:\n",
        "      best_result = sample\n",
        "      best_score = dist\n",
        "  return best_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMPXemZtNTI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_single(sid, train_file, test_instance, save_dest):\n",
        "  \"\"\"\n",
        "  Takes the single testing JSON file as a dict.\n",
        "  Runs sampling on all 3, saves results to dest dir, each training example to\n",
        "  its own file\n",
        "  \"\"\"\n",
        "  tf.reset_default_graph()\n",
        "  sess = gpt2.start_tf_sess()\n",
        "#   shutil.copyfile('drive/My Drive/checkpoint/run1/checkpoint', 'checkpoint/run1/checkpoint')\n",
        "  \n",
        "  gpt2.finetune(sess,\n",
        "                dataset=train_file,\n",
        "                steps=2,\n",
        "                print_every=5,\n",
        "                sample_every=1000,\n",
        "                sample_length=1,\n",
        "                restore_from='fresh',\n",
        "                save_every=30,\n",
        "                ) # don't want to save\n",
        "  print('finetune done')\n",
        "  results = []\n",
        "  for i in range(1,4):\n",
        "    inp = test_instance[\"test{}_input\".format(i)]\n",
        "    tru = test_instance[\"test{}_true\".format(i)]\n",
        "    id_ = test_instance[\"test{}_id\".format(i)]\n",
        "    # Shorten input\n",
        "    inp = inp[:inp.find('\\n', 200)] + '\\n'\n",
        "    # Generate random sample\n",
        "    print('Random sample')\n",
        "    samp_rand = sample_random(sess, inp)\n",
        "    print(samp_rand)\n",
        "    # Generate sentiment sample\n",
        "    ss = sid.polarity_scores(tru)\n",
        "    sentiment_vec = np.array([ss[\"compound\"], ss[\"neg\"], ss[\"neu\"], ss[\"pos\"]])\n",
        "    samp_sent = sample_sentiment(sess, inp, sentiment_vec)\n",
        "    sample = {\"id\": id_,\n",
        "              \"prefix\": inp,\n",
        "              \"truth\": tru,\n",
        "              \"random\": samp_rand,\n",
        "              \"sentiment\": samp_sent\n",
        "             }\n",
        "    results.append(sample)\n",
        "  with open(save_dest, \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "  print('finished test single')\n",
        "\n",
        "def run_tests(test_dir, train_dir):\n",
        "  # Load model from checkpoint\n",
        "  for f in sorted(listdir(train_dir))[0::4]:\n",
        "    fname = splitext(f)[0]\n",
        "    train = join(train_dir, f)\n",
        "    test = join(test_dir, fname+\".json\")\n",
        "    if isfile(train) and isfile(test):\n",
        "      with open(test, \"r\") as test_file:\n",
        "        test_instance = json.load(test_file)\n",
        "        print(f'Testing {fname}')\n",
        "        test_single(sid, train, test_instance, \"/content/drive/My Drive/text mining results/{}_sample.json\".format(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tG682gbVNp_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4155
        },
        "outputId": "c375969e-40e5-4834-b83e-55c87d620534"
      },
      "cell_type": "code",
      "source": [
        "run_tests('moviescriptmining/test_cases', 'moviescriptmining/training_cases')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing 10-Things-I-Hate-About-You\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 722.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 13286 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint/run1/model-2\n",
            "finetune done\n",
            "Random sample\n",
            "EGLISH CLASS - DAY \n",
            "A room full of bored seniors doodle and scare off into space MS. BLAISE, the one-step-away-from-medication English Teacher, tries to remember what she's talking about. \n",
            "MRS. BLAISE Well, then.  Oh, yes.  I guess that does it for our analysis of The Old Man and the Sea.  Any other comments? (with dread) Kat? \n",
            "MRS. BLAISE \"I was a little worried you were going to do something like that, but having your first Ph.D. is a special privilege. I'm still learning. I'm just worried about my country. I just want to go home and be a queen. I know you're a royal, but I'm not going to let you have your second Ph.D. When I get home, I'll be giving you a big hug, and I'll be standing there at the window, saying, 'I'm so glad you're here. You're the one where I work. I'm the one who knew my dad's name. I'm the one who got to be a part of the story. I'm the one who got to be the one to get the job done. I'm the one who got to be the one to get the job done. I'm the one who never gave up. I'm the one who never, ever gave up on the idea of being a queen. I'm the one who always had to be a queen. I'm the one who always had to be a queen. I'm the one that always had to be a monarch. I'm the one who never gave up on the idea of being a queen. I'm the one that never, ever gave up on the idea of being a queen. I'm the one who never gave up on the idea of being a queen. I'm the one who never gave up on the idea of being a queen. I'm the one who never gave up on the idea of being a queen. I'm the one who never\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "H motions to the remaining detention prisoners, without noticing Patrick's absence. \n",
            "Kat smiles at him. \n",
            "KAT Thank you, Mr. Chapin. \n",
            "Kat bolts out the door.  Mr. Chapin goes back to his muscle mag, wiping the sweat from his brow. \n",
            "Kat turns to him. \n",
            "\"My name is Patrick Chapin. I am the one who will be watching over you. I am currently on your case.\"\n",
            "\"What?\"\n",
            "\"My name is Patrick Chapin, and I am the man who made the decision to torture you. I am a man who has failed his students and employees, and I have no future as a teacher.\"\n",
            "Kat's hands trace the outlines of his name on the wall. \n",
            "He looks at Patrick and then at himself, and then finally at Patrick. \n",
            "\"You have nothing to lose. I can't help you, but I know that you will not be satisfied. You will not be a good student. You will not be a good person. You will not be able to live your life the way you deserve.\"\n",
            "\"What?\"\n",
            "\"You have been doing my job for over a year, and I am more than happy to give you an opportunity to improve. I will not let you down. I am a man who will not let you down. I have been making the decision that you will not be able to live your life the\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "I.  PROM - NIGHT \n",
            "Joey, drunk, disorderly and pissed off, walks in with a few stray jocks - also dateless.  He zeroes in on Cameron, now consoling a pissed-off Bianca. \n",
            "Patrick and Kat continue to slow dance, oblivious to the evil about to erupt. \n",
            "Cameron, still drunk, starts to leave. \n",
            "\"How's it gonna be?\" Kat asks, and looks up at Joe. \n",
            "\"It's just gonna be a weird, shitty relationship,\" Joe says, and walks over to Joe. \n",
            "\"And what's the point of this affair at all?\" Patrick asks, and Joe nods. \n",
            "\"I don't know. It's just a one-off.\"\n",
            "Joe, though, doesn't understand how this can be. \n",
            "\"Hey, you didn't do anything wrong, huh?\"\n",
            "\"I mean, it's just a one-off. You've had your responsibilities and your career over so long, and you're still in the town to get out of here. So you're not really in a position to decide who's in charge of the relationship.\"\n",
            "Joe looks at Patrick. \n",
            "\"I'm not even sure what that means,\" he says. \"And I'm sure you're going to want to keep it that way. But I don't want to give you a reason to do it.\"\n",
            "\"I'm not afraid of it,\" Patrick says. \"I just want to keep it as a normal part of my life. If\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "finished test single\n",
            "Testing 127-Hours\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 194.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 11396 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint/run1/model-2\n",
            "finetune done\n",
            "Random sample\n",
            "KISTI ... and suddenly there's a guy right behind you and `wait a minute, why is he wearing a HOCKEY \n",
            "MASK!' They all laugh. \n",
            "ARON Let me guess... You're here for the paintings or the Cathedral? \n",
            "KRISTI The Cathedral? We've got a bit disorientated and the map isn't great. Where is it? \n",
            "ARON I can't see it. It's a picture of the Cathedral, but I've got a map of the cathedral. I've been here for 2 hours. They're looking at me. And I've never seen anything like that. I can see the cathedral - but it's only a picture of the Cathedral. I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral, and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and I can see the Cathedral and\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "CUT TO: \n",
            "EXT. C/U. DAY. \n",
            "A small snake slithers away from his giant feet. \n",
            "CUT TO: \n",
            "EXT. BLUE JOHN CANYON. DAY. \n",
            "ARON Easy Aron, easy now. He keeps moving, descending still, but a little more circumspect. He lets the change of pace allow him to whip round his pack and with the practice of thousands of times selects and plays a CD without stopping, slipping the headphones over his head. \n",
            "ARON It's not like I have been hearing all day. I've been in the gym, I've been in the house, I've been in the shelter. I've been in the home, I've been in the bedroom. I've been in the bathroom. I've been in the kitchen. I've been in the bath. I've been in the kitchen, I've been in the house, I've been in the house, I've been in the bathroom. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack. He keeps looking at his pack\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "I. CANYON FROM UNDERNEATH SILHOUETTED AGAINST SKY. DAY. \n",
            "As before he squats and clambers down the back side of the stone to reduce his drop down. \n",
            "CUT TO: \n",
            "INT. CANYON. DAY. C/U TIGHT ON ARON. \n",
            "Just as he dangles there's a scraping sound, small but close, too close and the stone judders towards him, pulled by the torque of his weight on his side, rotating. Instantly and instinctively he lets go and drops. Like he's trying to detach a mine dragging him to the sea floor. \n",
            "CUT TO: \n",
            "INT. CANYON. DAY. C/U TIGHT ON ARON. \n",
            "He's trying to stop the slide, but there are no moves or force to stop it. He's trying to go up on the stone, but the stone is too strong. He's trying to go down, but the stones are too heavy. He finally lets go and he's going down. Losing weight on his side. He needs to be able to lift himself up and down. He doesn't want to be in that position. \n",
            "CUT TO: \n",
            "INT. CANYON. DAY. C/U TIGHT ON ARON. \n",
            "He's holding on, but the stone whirrs and the stone is shaking. He's dragging himself down. He's trying to climb, but the stone is too heavy. It's too heavy. He's trying to climb up on the stone to go up. The stone is too heavy. He's waiting to push himself up. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. It's too heavy. It's too heavy. It's too heavy. It's too heavy. It's too heavy. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. It's too heavy. It's too heavy. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. It's too heavy. It's too heavy. It's too heavy. It's too heavy. It's too heavy. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking. He's holding on, but the stone is shaking.\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "finished test single\n",
            "Testing 187\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 24759 tokens\n",
            "Training...\n",
            "Saving checkpoint/run1/model-2\n",
            "finetune done\n",
            "Random sample\n",
            "Trevor hastily rifles through the teacher's drawers.     A startling discovery abruptly halts his search... \n",
            "CLOSER now INTO a brown paper bag Trevor has opened. Inside the bag is a .357 Magnum. \n",
            "OFF Trevor's narrowing gaze, an offstage voice interrupts... \n",
            "\"What the hell is this?\"\n",
            "\"Well, I'm not sure - I was just thinking about the one thing I saw that killed my friend, and I'm getting a little tired of it. \n",
            "\"It's a .357, a .357, this thing. \n",
            "\"I'm going to go get it, then I'll go get it. \n",
            "\"I'm going to get it. \n",
            "\"What, what? \n",
            "\"This is the one thing I really don't know. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it is. \n",
            "\"I don't know what it\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "TREVOR I have. \n",
            "ELLEN (absently) Last week Benny and his tagging crew had Ms. Eskander pinned in the corner over there. (pointing) ... She's seven months pregnant and he's tormenting her with a broom handle... Can I help you with those? \n",
            "ELLEN (dramatically) Don't be a jerk. You're a real gentleman. \n",
            "ELLEN (pointing) ... If it wasn't for you I'd still be here. \n",
            "ELLEN It's not like I can see you getting upset. (pointing) You don't. It's just that I'm a good guy. \n",
            "ELLEN You don't? It's just that I'm a real gentleman. \n",
            "ELLEN (shouting) That's not a good guy. \n",
            "ELLEN (unintelligible) It's a good guy. \n",
            "ELLEN ... You're a real gentleman. \n",
            "ELLEN No, not a real gentleman. \n",
            "ELLEN (entering into the bar) You don't get to be the only one. \n",
            "ELLEN (pointing) Do you want to be the only one? \n",
            "ELLEN (points at the door) No, I don't. \n",
            "ELLEN (pointing) No, I don't. \n",
            "ELLEN (pointing) I'll give it to you. (pointing) You're going to give it to\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "Trevor nods, sustains an awkward smile. \n",
            "TREVOR Has nothing to do with you, Ellen. It's... hard for me... \n",
            "A struggle, fighting against his true feelings... \n",
            "TREVOR Pretty much been like that since... you know, my accident. Has nothing to do with you. \n",
            "Trevor glances around. \n",
            "TREVOR Blasphes, but you don't want to hurt him. \n",
            "TREVOR You can't hurt him if you want to. \n",
            "Trevor's eyes widen. \n",
            "TREVOR You can't. \n",
            "Trevor's eyes widen. \n",
            "TREVOR You don't want to. \n",
            "Trevor frowns. \n",
            "TREVOR No. \n",
            "Trevor frowns. \n",
            "TREVOR What do you mean by that? \n",
            "TREVOR No. \n",
            "Trevor frowns. \n",
            "TREVOR No, I mean... \n",
            "Trevor's eyes go wide. \n",
            "TREVOR You mean that? \n",
            "Trevor's eyes go wide. \n",
            "TREVOR No. \n",
            "Trevor's eyes go wide. \n",
            "TREVOR That's the one thing I'm afraid of. \n",
            "Trevor's eyes go wide. \n",
            "TREVOR You know what? \n",
            "Trevor looks at him. \n",
            "TREVOR You know, I don't like it when\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "finished test single\n",
            "Testing 30-Minutes-or-Less\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 15004 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint/run1/model-2\n",
            "finetune done\n",
            "Random sample\n",
            "DWAYNE (CONT'D) You go anywhere near a police station, and Fourth of July comes early this year. \n",
            "Dwayne nods at the timer on the side of the vest. \n",
            "DWAYNE It's 9:00 AM. You got 8 hours. \n",
            "He hands Will a slip of paper. \n",
            "EVEY (CONT'D) It's just a piece of paper. I'll take it back. Let's go. I can't forget it. \n",
            "DWAYNE (CONT'D) We're not here to kill you, you know. We're here to help you. We're here to get you to safety. We're here so you can help yourself. We're here to take care of you. We're here to be your friend. You're never going to ask me for anything. We're there to help you. We're here to help you. We're here to make sure that you're safe. We're here to make sure that you're safe. And we're here because we got to. We're here because we got to. We got to make sure you're safe. We're here to make sure that you're safe. We're here because we got to. We're there because we got to. We got to make sure you're safe. We're here because we got to. We're here because we got to. We\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n",
            "Sentiment sample 3\n",
            "Sentiment sample 4\n",
            "Random sample\n",
            "W waves at her from where he is standing, way across on the other side of the roof. Kate starts toward him. \n",
            "WILL Stop! \n",
            "Will takes out his cell phone and dials. Kate's phone rings. She answers it, confused. \n",
            "KATE No! I'm so sorry. I couldn't help it. This is my real boyfriend. I'm not your real boyfriend. I've always been your friend. You were my best friend, and I'm really sorry. I'm sorry. I'm sorry. I can't win. I can't give up. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm so sorry! I can't let this happen to you! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! I can't let this happen to anyone! \"What's wrong?\" \"I just don't know what to do.\" \"Are\n",
            "Sentiment sample 0\n",
            "Sentiment sample 1\n",
            "Sentiment sample 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KW_P3hFStcnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}